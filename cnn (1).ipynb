{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmMAJJm--QAu"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odQNK9tP_k4Z"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6v4KNvy_vyV"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1c0XlyBXN14bZVCmGNPqmbbjbF_izK8QO'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Indian_pines_corrected.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay_Adgrf_wLb"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1SY9x4A04lm_VCbj6ngoBSFcZkw0RN718'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Indian_pines_gt.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pRnv-E__6eJ"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1KQJXsYxGW6XR5U2nM_m_DfDsjdGd-LeA'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Indian_pines.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTtEkDmAEshs"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1xOtRP0cYqKevTDkGDcVupFz-MiTXS0zV'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Indian_pines_corrected1.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJPRIn4-Esyj"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1XCZwlkfeBStISVuSas9TGUq4ijQf_qiE'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Indian_pines_gt1.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giTfMkWE_6pe"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.io as sio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import os\n",
        "import random\n",
        "from random import shuffle\n",
        "from skimage.transform import rotate\n",
        "import scipy.ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh0nzNQuAwKV"
      },
      "source": [
        "def loadIndianPinesData():\n",
        "    data = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
        "    labels = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
        "    \n",
        "    return data, labels\n",
        "\n",
        "def splitTrainTestSet(X, y, testRatio=0.10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=345,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def oversampleWeakClasses(X, y):\n",
        "    uniqueLabels, labelCounts = np.unique(y, return_counts=True)\n",
        "    maxCount = np.max(labelCounts)\n",
        "    labelInverseRatios = maxCount / labelCounts  \n",
        "    # repeat for every label and concat\n",
        "    newX = X[y == uniqueLabels[0], :, :, :].repeat(round(labelInverseRatios[0]), axis=0)\n",
        "    newY = y[y == uniqueLabels[0]].repeat(round(labelInverseRatios[0]), axis=0)\n",
        "    for label, labelInverseRatio in zip(uniqueLabels[1:], labelInverseRatios[1:]):\n",
        "        cX = X[y== label,:,:,:].repeat(round(labelInverseRatio), axis=0)\n",
        "        cY = y[y == label].repeat(round(labelInverseRatio), axis=0)\n",
        "        newX = np.concatenate((newX, cX))\n",
        "        newY = np.concatenate((newY, cY))\n",
        "    np.random.seed(seed=42)\n",
        "    rand_perm = np.random.permutation(newY.shape[0])\n",
        "    newX = newX[rand_perm, :, :, :]\n",
        "    newY = newY[rand_perm]\n",
        "    return newX, newY\n",
        "\n",
        "def standartizeData(X):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    scaler = preprocessing.StandardScaler().fit(newX)  \n",
        "    newX = scaler.transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1],X.shape[2]))\n",
        "    return newX, scaler\n",
        "\n",
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca\n",
        "\n",
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX\n",
        "\n",
        "def createPatches(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels\n",
        "\n",
        "\n",
        "def AugmentData(X_train):\n",
        "    for i in range(int(X_train.shape[0]/2)):\n",
        "        patch = X_train[i,:,:,:]\n",
        "        num = random.randint(0,2)\n",
        "        if (num == 0):\n",
        "            \n",
        "            flipped_patch = np.flipud(patch)\n",
        "        if (num == 1):\n",
        "            \n",
        "            flipped_patch = np.fliplr(patch)\n",
        "        if (num == 2):\n",
        "            \n",
        "            no = random.randrange(-180,180,30)\n",
        "            flipped_patch = scipy.ndimage.interpolation.rotate(patch, no,axes=(1, 0),\n",
        "                                                               reshape=False, output=None, order=3, mode='constant', cval=0.0, prefilter=False)\n",
        "    \n",
        "    \n",
        "    patch2 = flipped_patch\n",
        "    X_train[i,:,:,:] = patch2\n",
        "    \n",
        "    return X_train\n",
        "\n",
        "\n",
        "def savePreprocessedData(X_trainPatches, X_testPatches, y_trainPatches, y_testPatches, windowSize, wasPCAapplied = False, numPCAComponents = 0, testRatio = 0.25):\n",
        "    if wasPCAapplied:\n",
        "        with open(\"X_trainPatches_\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, X_trainPatches)\n",
        "        with open(\"X_testPatches_\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, X_testPatches)\n",
        "        with open(\"y_trainPatches_\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, y_trainPatches)\n",
        "        with open(\"y_testPatches_\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, y_testPatches)\n",
        "    else:\n",
        "        with open(\"../preprocessedData/XtrainWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, X_trainPatches)\n",
        "        with open(\"../preprocessedData/XtestWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, X_testPatches)\n",
        "        with open(\"../preprocessedData/ytrainWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, y_trainPatches)\n",
        "        with open(\"../preprocessedData/ytestWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
        "            np.save(outfile, y_testPatches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC1ucMcXAwRt"
      },
      "source": [
        "numPCAcomponents = 30\n",
        "windowSize = 5\n",
        "testRatio = 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7FpA7-SAwaz"
      },
      "source": [
        "X, y = loadIndianPinesData()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCHMiVrAwlf"
      },
      "source": [
        "X,pca = applyPCA(X,numPCAcomponents)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY0JwRZnKrW3"
      },
      "source": [
        "XPatches, yPatches = createPatches(X, y, windowSize=windowSize)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMC4GnQsKrl-"
      },
      "source": [
        "X_train, X_test, y_train, y_test = splitTrainTestSet(XPatches, yPatches, testRatio)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p-bTbuOKrxQ"
      },
      "source": [
        "X_train, y_train = oversampleWeakClasses(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqJERxaaK3-6"
      },
      "source": [
        "X_train = AugmentData(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hvo8qXK4E3"
      },
      "source": [
        "savePreprocessedData(X_train, X_test, y_train, y_test, windowSize = windowSize, \n",
        "                     wasPCAapplied=True, numPCAComponents = numPCAcomponents,testRatio = testRatio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IK216yuLAur"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend as K\n",
        "#K.set_image_data_format('th')\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx8daRtTLA1-"
      },
      "source": [
        "\n",
        "X_train = np.load(\"X_trainPatches_\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio)  + \".npy\")\n",
        "\n",
        "y_train = np.load(\"y_trainPatches_\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfGVKSxCLA7M"
      },
      "source": [
        "# Reshape into (numberofsamples, channels, height, width)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[3], X_train.shape[1], X_train.shape[2]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO2RkqAyLA_z"
      },
      "source": [
        "# convert class labels to on-hot encoding\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDrKIjNuMfuD",
        "outputId": "8fc72a06-0eb6-48da-fe02-e3ecca12a028"
      },
      "source": [
        "# Define the input shape \n",
        "\n",
        "input_shape= X_train[0].shape\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 5, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFMMkExMMfvh"
      },
      "source": [
        "# number of filters\n",
        "C1 = 3*numPCAcomponents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZqhpD9aMfzC"
      },
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(C1, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(3*C1, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6*numPCAcomponents, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v17d3xyHMf10"
      },
      "source": [
        "\n",
        "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlRRQKtFM0Ys",
        "outputId": "dd246ddf-1eda-4656-b983-2ef94ffb90b7"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=15)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "928/928 [==============================] - 56s 59ms/step - loss: 2.6404 - accuracy: 0.1738\n",
            "Epoch 2/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 1.8342 - accuracy: 0.5299\n",
            "Epoch 3/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 1.1414 - accuracy: 0.6736\n",
            "Epoch 4/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 0.8352 - accuracy: 0.7377\n",
            "Epoch 5/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 0.6892 - accuracy: 0.7750\n",
            "Epoch 6/15\n",
            "928/928 [==============================] - 55s 60ms/step - loss: 0.5971 - accuracy: 0.8051\n",
            "Epoch 7/15\n",
            "928/928 [==============================] - 61s 65ms/step - loss: 0.5519 - accuracy: 0.8175\n",
            "Epoch 8/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 0.4929 - accuracy: 0.8367\n",
            "Epoch 9/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 0.4498 - accuracy: 0.8504\n",
            "Epoch 10/15\n",
            "928/928 [==============================] - 54s 59ms/step - loss: 0.4274 - accuracy: 0.8608\n",
            "Epoch 11/15\n",
            "928/928 [==============================] - 54s 58ms/step - loss: 0.3981 - accuracy: 0.8693\n",
            "Epoch 12/15\n",
            "928/928 [==============================] - 55s 59ms/step - loss: 0.3591 - accuracy: 0.8851\n",
            "Epoch 13/15\n",
            "928/928 [==============================] - 54s 58ms/step - loss: 0.3489 - accuracy: 0.8869\n",
            "Epoch 14/15\n",
            "928/928 [==============================] - 54s 58ms/step - loss: 0.3317 - accuracy: 0.8908\n",
            "Epoch 15/15\n",
            "928/928 [==============================] - 54s 58ms/step - loss: 0.3074 - accuracy: 0.9023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f933373af98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyO1DyoFM0ah"
      },
      "source": [
        "import h5py\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kn8BTmDM0eW"
      },
      "source": [
        "model.save('my_model' + str(windowSize) + 'PCA' + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + '.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWTfzhKGP8WQ"
      },
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "#import spectral\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eI_2VkDP8X-"
      },
      "source": [
        "def reports (X_test,y_test):\n",
        "    Y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
        "               ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
        "                'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
        "               'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
        "               'Stone-Steel-Towers']\n",
        "\n",
        "    \n",
        "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
        "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "    Test_Loss =  score[0]*100\n",
        "    Test_accuracy = score[1]*100\n",
        "\n",
        "    \n",
        "    \n",
        "    return classification, confusion, Test_Loss, Test_accuracy\n",
        "\n",
        "\n",
        "def applyPCA(X, numPCAcomponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numPCAcomponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numPCAcomponents))\n",
        "    return newX, pca\n",
        "\n",
        "def Patch(data,height_index,width_index):\n",
        "    #transpose_array = data.transpose((2,0,1))\n",
        "    #print transpose_array.shape\n",
        "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
        "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
        "    patch = data[height_slice, width_slice, :]\n",
        "    \n",
        "    return patch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dDQpIHTP8bp"
      },
      "source": [
        "X_test = np.load(\"X_testPatches_\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
        "\n",
        "\n",
        "y_test = np.load(\"y_testPatches_\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMleo-wzP8el"
      },
      "source": [
        "X_test  = np.reshape(X_test, (X_test.shape[0], X_test.shape[3], X_test.shape[1], X_test.shape[2]))\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZea5um6Rb-l"
      },
      "source": [
        "# load the model architecture and weights\n",
        "model = load_model('my_model' + str(windowSize) + 'PCA' + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + '.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiQnLO6vRcJT",
        "outputId": "68858462-07fc-4a00-c18c-c96db4eb4ecc"
      },
      "source": [
        "# Using the pretrained model make predictions and print the results into a report\n",
        "classification, confusion, Test_loss, Test_accuracy = reports(X_test,y_test)\n",
        "classification = str(classification)\n",
        "confusion = str(confusion)\n",
        "file_name = 'report' + \"WindowSize\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) +\".txt\"\n",
        "with open(file_name, 'w') as x_file:\n",
        "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{} classification(%)'.format(classification))\n",
        "    x_file.write('\\n')\n",
        "    x_file.write('{}'.format(confusion))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81/81 [==============================] - 1s 13ms/step - loss: 0.4393 - accuracy: 0.8502\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}